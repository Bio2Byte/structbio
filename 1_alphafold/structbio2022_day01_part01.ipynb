{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c05c7e1-2830-4a7b-ac9e-55b245752562",
   "metadata": {
    "tags": []
   },
   "source": [
    "Structural biology - Practical day 01\n",
    "=======================================\n",
    "\n",
    "Part 01\n",
    "-------\n",
    "\n",
    "Document written by [AdriÃ¡n Diaz](mailto:adrian.diaz@vub.be) & [David Bickel](mailto:david.bickel@vub.be)\n",
    "\n",
    "**Vrije Universiteit Brussel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa3d3a-1485-4534-80f4-276b851954b7",
   "metadata": {},
   "source": [
    "## The scenario\n",
    "\n",
    "We have these proteins involved: \n",
    "\n",
    "- Gyrase (dimer) `Gyr:Gyr`\n",
    "- Toxin (dimer) `CcdB:CcdB`\n",
    "- Anti-toxin `CcdA`\n",
    "\n",
    "### Sequences\n",
    "\n",
    "The following code block contains the residues of both Toxin and Anti-toxin proteins in FASTA format. You will use them to create the prediction job.\n",
    "\n",
    "```fasta\n",
    ">CcdA\n",
    "MKQRITVTVDSDSYQLLKAYDVNISGLVSTTMQNEARRLRAERWKAENQEGMAEVARFIEMNGSFADENRDW\n",
    "\n",
    ">CcdB\n",
    "MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKVSRELYPVVHIGDESWRMMTTDMASVPVSVIGEEVADLSHRENDIKNAINLMFWGI\n",
    "```\n",
    "\n",
    "### Task A\n",
    "Predict the following complexes using ColabFold:\n",
    "\n",
    "- Group A: `CcdB:CcdB:CcdA`\n",
    "- Group B: `CcdB:CcdB`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe22ff-6f27-4ee0-a6fc-b170afa73f50",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AlphaFold2 Job\n",
    "AlphaFold is installed for the Nvidia Ampere GPUs in Hydra. Submit your jobs with the options `--gpus-per-node=1 --partition=ampere_gpu` to specifically request one of those GPUs.\n",
    "\n",
    "```bash\n",
    "python3 docker/run_docker.py \\\n",
    "  --fasta_paths=sequences.fasta \\\n",
    "  --max_template_date=2021-11-01 \\\n",
    "  --model_preset=multimer \\\n",
    "  --data_dir=$DOWNLOAD_DIR \\\n",
    "  --output_dir=/home/user/absolute_path_to_the_output_dir\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6fa02",
   "metadata": {},
   "source": [
    "#### Group A\n",
    "\n",
    "`CcdB:CcdB:CcdA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b298a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name         = \"structbio_multimer\"\n",
    "input_name       = \"multimer.fasta\"\n",
    "output_path      = \"multimer\"\n",
    "\n",
    "prediction_input = \"\"\"\n",
    ">CcdB_1\n",
    "MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKVSRELYPVVHIGDESWRMMTTDMASVPVSVIGEEVADLSHRENDIKNAINLMFWGI\n",
    "\n",
    ">CcdB_2\n",
    "MQFKVYTYKRESRYRLFVDVQSDIIDTPGRRMVIPLASARLLSDKVSRELYPVVHIGDESWRMMTTDMASVPVSVIGEEVADLSHRENDIKNAINLMFWGI\n",
    "\n",
    ">ccdA_1\n",
    "MKQRITVTVDSDSYQLLKAYDVNISGLVSTTMQNEARRLRAERWKAENQEGMAEVARFIEMNGSFADENRDW\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c4fc5",
   "metadata": {},
   "source": [
    "#### Group B\n",
    "\n",
    "`CcdB:CcdB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd147a2-bcd0-4cd6-bffe-d975918cbd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name         = \"structbio_multimer\"\n",
    "input_name       = \"multimer.fasta\"\n",
    "output_path      = \"multimer\"\n",
    "\n",
    "prediction_input = \"\"\"\n",
    ">ccdA_1\n",
    "MKQRITVTVDSDSYQLLKAYDVNISGLVSTTMQNEARRLRAERWKAENQEGMAEVARFIEMNGSFADENRDW\n",
    "\n",
    ">_ccdA_2\n",
    "MKQRITVTVDSDSYQLLKAYDVNISGLVSTTMQNEARRLRAERWKAENQEGMAEVARFIEMNGSFADENRDW\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcbc277",
   "metadata": {},
   "source": [
    "#### Creating the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d524492c-2028-486a-8d00-5e3b0af41aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create input directory\n",
    "mkdir -p ./input\n",
    "\n",
    "# Create output directory\n",
    "mkdir -p ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe10ec-f25c-4154-b552-5184847fc089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_path = os.path.abspath(os.path.join('./input', input_name))\n",
    "\n",
    "print(\"Saving input file in\", input_path)\n",
    "\n",
    "with open(input_path, \"w\") as file_handler:\n",
    "    file_handler.write(prediction_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5723cf1-9630-43b9-b3fc-487df5209044",
   "metadata": {
    "tags": []
   },
   "source": [
    "### About Slurm jobs in Hydra\n",
    "\n",
    "Slurm provides a complete toolbox to manage and control your jobs. Some of them carry out common tasks: \n",
    "\n",
    "- submitting job scripts to the queue (`sbatch`)\n",
    "- printing information about the queue (`mysqueue`)\n",
    "\n",
    "Jobs are descripted using Bash files with these header options:\n",
    "\n",
    "- `--job-name=job_name` : Set job name to job_name\n",
    "- `--time=DD-HH:MM:SS`: Define the time limit\n",
    "- `--mail-type=BEGIN|END|FAIL|REQUEUE|ALL`: Conditions for sending alerts by email\n",
    "- `--partition=cluster_type`: Request a cluster\n",
    "\n",
    "\n",
    "More information: https://hpc.vub.be/docs/job-submission/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6614114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_job = \"\"\"\n",
    "#!/bin/bash\n",
    "\n",
    "# SCRIPT RESOURCE CONFIG:\n",
    "#SBATCH --partition=ampere_gpu\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --gpus-per-node=1\n",
    "#SBATCH --cpus-per-gpu=16\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --time=02:00:00\n",
    "#SBATCH --reservation=structbio1\n",
    "\n",
    "# LOADING CUDA (GPU) DEPENDENCIES:\n",
    "export CUDA_MPS_PIPE_DIRECTORY=$TMPDIR/nvidia-mps-pipe\n",
    "export CUDA_MPS_LOG_DIRECTORY=$TMPDIR/nvidia-mps-log\n",
    "nvidia-cuda-mps-control -d\n",
    "\n",
    "# LOADING ALPHAFOLD IN MEMORY:\n",
    "module load AlphaFold/2.3.1-foss-2022a-CUDA-11.7.0\n",
    "\n",
    "# SETUP INPUT/OUTPUT FILES\n",
    "BASE_DIR={wrkdir}\n",
    "mkdir -p $BASE_DIR/output/{output_path}\n",
    "\n",
    "# LAUNCH ALPHAFOLD\n",
    "run_alphafold.py \\\n",
    "    --model_preset=monomer_casp14 \\\n",
    "    --fasta_paths=$BASE_DIR/{input_name} \\\n",
    "    --max_template_date=2999-12-31 \\\n",
    "    --output_dir=$BASE_DIR/output/{output_path}\n",
    "\"\"\".format(job_name=job_name, input_name=input_name, output_path=output_path, wrkdir=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82ba56-00da-40bf-88f6-732325bab3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_path = os.path.join(\"./input\", job_name + \".sh\")\n",
    "\n",
    "print(\"Saving job file in\", job_path)\n",
    "\n",
    "with open(job_path, \"w\") as file_handler:\n",
    "    file_handler.write(prediction_job)\n",
    "\n",
    "print(\"Job file saved in\", job_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33a9bec-ed59-47bc-b9ed-edb8befb4bcd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Job enqueueing\n",
    "\n",
    "The job is submitted using the command `sbatch` followed by the name of our job file. You will receive a job identifier as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526f3d3-344a-4597-bd6f-8004dd52d00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "process = subprocess.Popen(['sbatch', job_path],\n",
    "                     stdout=subprocess.PIPE,\n",
    "                     stderr=subprocess.PIPE)\n",
    "\n",
    "stdout, stderr = process.communicate()\n",
    "return_code    = process.poll()\n",
    "\n",
    "print(f\"stdout (exit code={return_code}):\")\n",
    "for line in stdout.decode().split(\"\\n\"):\n",
    "    print(line)\n",
    "\n",
    "print(f\"stderr (exit code={return_code}):\")\n",
    "for line in stderr.decode().split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c54f0a-9ee0-41b6-af70-581fcbb846e4",
   "metadata": {},
   "source": [
    "### Query the queue status\n",
    "The command to run is `mysqueue`. While the job is running you could visualize the SLURM logs inside the `slurm-JOBID.out` file:\n",
    "\n",
    "- Cat command: View the full content of the file. `cat slurm-JOBID.out`\n",
    "- Tail command: View the last lines of the file. `tail -f slurm-JOBID.out` (with `-f` the command will follow the output automatically)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33f3e9-2e87-4a01-9220-eb291ebf3663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "process = subprocess.Popen(['mysqueue'],\n",
    "                     stdout=subprocess.PIPE,\n",
    "                     stderr=subprocess.PIPE)\n",
    "\n",
    "stdout, stderr = process.communicate()\n",
    "return_code    = process.poll()\n",
    "\n",
    "print(f\"stdout (exit code={return_code}):\")\n",
    "for line in stdout.decode().split(\"\\n\"):\n",
    "    print(line)\n",
    "\n",
    "print(f\"stderr (exit code={return_code}):\")\n",
    "for line in stderr.decode().split(\"\\n\"):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773893b3-70ee-4a8e-b3bb-33f0c3548caa",
   "metadata": {},
   "source": [
    "We are ready to continue working on the next Jupyter Notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
